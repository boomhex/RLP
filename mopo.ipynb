{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9087d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/usr/lib/x86_64-linux-gnu/libGLEW.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/usr/lib/x86_64-linux-gnu/libGLEW.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/usr/lib/x86_64-linux-gnu/libGLEW.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: h5py in /home3/s5228786/.local/lib/python3.10/site-packages (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home3/s5228786/.local/lib/python3.10/site-packages (from h5py) (2.2.6)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e81ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NN necessities:\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# import plotting utilities:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import data preprocessing utilities:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2718ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):   # class defining a basic nn\n",
    "\n",
    "    def __init__(self, h_size=200, h_layers=4):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(23, h_size),      # in\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        for i in range(h_layers):\n",
    "            self.model.append(nn.Linear(h_size, h_size))\n",
    "            self.model.append(nn.ReLU())\n",
    "        self.mean_head = nn.Linear(h_size, 18)\n",
    "        self.logvar_head = nn.Linear(h_size, 18)\n",
    "\n",
    "        # bind log-variance to avoid numerical instability\n",
    "        self.max_logvar = nn.Parameter(torch.ones(18) * 0.5)\n",
    "        self.min_logvar = nn.Parameter(torch.ones(18) * -10)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.criterion = nn.MSELoss()    # using mean squared error as a loss metric\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.model(x)\n",
    "        mean = self.mean_head(res)\n",
    "        logvar = self.logvar_head(res)\n",
    "\n",
    "        # clamp log-variance using soft constraints (see MBPO/PETS)\n",
    "        logvar = self.max_logvar - torch.nn.functional.softplus(self.max_logvar - logvar)\n",
    "        logvar = self.min_logvar + torch.nn.functional.softplus(logvar - self.min_logvar)\n",
    "        return mean, logvar\n",
    "\n",
    "    def nll_loss(self, x, y):\n",
    "        \"\"\"\n",
    "        Negative log-likelihood of Gaussian:\n",
    "            NLL = 0.5 * [ logσ² + (y - µ)² / σ² ]\n",
    "        \"\"\"\n",
    "        mean, logvar = self.forward(x)\n",
    "        var = torch.exp(logvar)\n",
    "\n",
    "        nll = 0.5 * ((y - mean)**2 / var + logvar)\n",
    "        return nll.mean()\n",
    "\n",
    "    def train_epoch(self, x, y):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        loss = self.nll_loss(x, y)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def train(self, train_data, epochs=500, cp=100, surpress=False):\n",
    "        x, y = train_data\n",
    "\n",
    "        # again split the data to optimize hyperparam on val set, not leak data.\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "    \n",
    "        test_losses = []\n",
    "        losses = []\n",
    "    \n",
    "        for iter in range(epochs):\n",
    "            # train\n",
    "            iteration_loss = self.train_epoch(x_train, y_train)\n",
    "            losses.append(iteration_loss)\n",
    "\n",
    "            # validate\n",
    "            val_loss = self.validation_loss((x_val, y_val))\n",
    "            test_losses.append(val_loss)\n",
    "    \n",
    "            # print\n",
    "            if not surpress:\n",
    "                if iter and iter % cp == 0:    # update on iteration checkpoints\n",
    "                    print(f\"iteration {iter}/{epochs}, loss = train: {iteration_loss}, val: {val_loss}\")\n",
    "\n",
    "        return losses, test_losses\n",
    "\n",
    "\n",
    "    def validation_loss(self, test_data):\n",
    "        x, y = test_data\n",
    "        loss = self.nll_loss(x, y)\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b73864f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self, n_networks, lmbda=0.5, hidden_size=10):\n",
    "        self.n_networks = n_networks\n",
    "        self.ensemble = [Network(h_size=hidden_size) for i in range(n_networks)]\n",
    "        self.lmbda = lmbda\n",
    "\n",
    "    def train(self, train_data):\n",
    "        for model in self.ensemble:\n",
    "            model.train(train_data, surpress=True)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions = [ model.forward(x) for model in self.ensemble ]\n",
    "        # 7 x 2 x N x 18 \n",
    "        \n",
    "        # separate means and variances\n",
    "        means = []\n",
    "        variances = []\n",
    "        for m, v in predictions:\n",
    "            print(\"sep\")\n",
    "            means.append(m)\n",
    "            variances.append(v)\n",
    "    \n",
    "        for i in range(len(variances)):\n",
    "            print(variances[i].shape)\n",
    "            variances[i] = variances[i].square().sum(dim=1).sqrt()  # convert each to mean variance\n",
    "        print(variances) \n",
    "        \n",
    "#         max_var = max(variance)\n",
    "#         random_mean = mean[random.randint(0, self.n_networks)]\n",
    "        \n",
    "#         random_mean = self.correct_reward(random_mean, max_variance)\n",
    "#         return random_mean\n",
    "    \n",
    "    def correct_reward(self, mean, max_var):\n",
    "        mean[-1] = mean[-1] - self.lmbda * max_var\n",
    "        return mean\n",
    "    \n",
    "    def mse(self, y, y_hat):\n",
    "        return torch.mean( (y - y_hat)**2 )\n",
    "\n",
    "    def test(self, test_data):\n",
    "        x_test, y_test = test_data\n",
    "        prediction = self.predict(x_test)\n",
    "        return self.mse(prediction, y_test)\n",
    "\n",
    "    def to(self, device):\n",
    "        for model in self.ensemble:\n",
    "            model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c63b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['actions', 'infos', 'metadata', 'next_observations', 'observations', 'rewards', 'terminals', 'timeouts']>\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = h5py.File(Path(\"./halfcheetah_medium-v2.hdf5\"))\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b8db56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape = (1000000, 6)\n",
      "s shape = (1000000, 17)\n",
      "s_new shape = (1000000, 17)\n",
      "r shape = (1000000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract relevant cols\n",
    "a = data[\"actions\"]\n",
    "s_new = data[\"next_observations\"]\n",
    "s = data[\"observations\"]\n",
    "r = data[\"rewards\"]\n",
    "\n",
    "# info\n",
    "print(\n",
    "    f\"a shape = {a.shape}\\n\" \\\n",
    "    f\"s shape = {s.shape}\\n\" \\\n",
    "    f\"s_new shape = {s_new.shape}\\n\" \\\n",
    "    f\"r shape = {r.shape}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21844542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "x_train shape = torch.Size([800000, 23])\n",
      "x_test shape = torch.Size([200000, 23])\n",
      "y_train shape = torch.Size([800000, 18])\n",
      "y_test shape = torch.Size([200000, 18])\n"
     ]
    }
   ],
   "source": [
    "# divide data\n",
    "x = np.hstack([a, s])                                # -> (N, 23)\n",
    "y = np.hstack([s_new, np.array(r).reshape(-1, 1)])   # -> (N, 18)\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# converting to tensors\n",
    "x = torch.tensor(x, dtype=torch.float32).to(device)   \n",
    "y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "# info\n",
    "print(\n",
    "    f\"x_train shape = {x_train.shape}\\n\" \\\n",
    "    f\"x_test shape = {x_test.shape}\\n\" \\\n",
    "    f\"y_train shape = {y_train.shape}\\n\" \\\n",
    "    f\"y_test shape = {y_test.shape}\"\n",
    ")\n",
    "# set_data\n",
    "train_data = (x_train, y_train)\n",
    "test_data = (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "\n",
    "\n",
    "# set params\n",
    "epochs = 100\n",
    "\n",
    "# for network_width in width_list:\n",
    "model = Network( h_size=10 )\n",
    "model = model.to(device)\n",
    "\n",
    "# train\n",
    "train_losses, test_losses = model.train(train_data, epochs=epochs, cp=10)\n",
    "# test_results.append(test_losses)\n",
    "test_loss = model.nll_loss(x_test, y_test)\n",
    "print(f\"final test loss = {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cad589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "x = np.arange(0, epochs)\n",
    "ax.plot(x, train_losses, label='train', color='red')\n",
    "ax.plot(x, test_losses, label='test', color='green')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot size/performance comparison\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "x = width_list\n",
    "ax.set_title(\"epochs = 1000\")\n",
    "for i, w in enumerate(x):\n",
    "    ax.plot(np.arange(0, epochs), test_results[i], label=w)\n",
    "ax.set_xlabel(\"epochs\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ed59497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ensemble\n",
    "\n",
    "ensemble = Ensemble(7, hidden_size=10)\n",
    "ensemble.to(device)\n",
    "# ensemble.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76d538bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sep\n",
      "sep\n",
      "sep\n",
      "sep\n",
      "sep\n",
      "sep\n",
      "sep\n",
      "torch.Size([200000, 18])\n",
      "torch.Size([200000, 18])\n",
      "torch.Size([200000, 18])\n",
      "torch.Size([200000, 18])\n",
      "torch.Size([200000, 18])\n",
      "torch.Size([200000, 18])\n",
      "torch.Size([200000, 18])\n",
      "[tensor([2.2276, 2.2450, 2.2383,  ..., 2.2106, 2.2086, 2.2547], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>), tensor([2.0179, 2.0168, 2.0205,  ..., 2.0184, 2.0163, 2.0197], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>), tensor([2.1840, 2.1902, 2.1866,  ..., 2.1882, 2.1858, 2.1890], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>), tensor([1.9650, 1.9679, 1.9656,  ..., 1.9772, 1.9693, 1.9658], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>), tensor([2.0143, 2.0565, 2.0605,  ..., 2.0489, 2.0168, 2.0602], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>), tensor([2.1824, 2.1621, 2.1653,  ..., 2.1695, 2.1877, 2.1665], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>), tensor([2.1263, 2.1279, 2.1308,  ..., 2.1316, 2.1349, 2.1323], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mensemble\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [19], line 44\u001b[0m, in \u001b[0;36mEnsemble.test\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m     42\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m test_data\n\u001b[1;32m     43\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [19], line 39\u001b[0m, in \u001b[0;36mEnsemble.mse\u001b[0;34m(self, y, y_hat)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, y_hat):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean( (\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m )\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "ensemble.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911ca9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
