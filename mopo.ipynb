{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9087d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NN necessities:\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# import plotting utilities:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import data preprocessing utilities:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2718ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):   # class defining a basic nn\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(23, 200),      # in\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 200),    # hidden\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 18)       # out\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.criterion = nn.MSELoss()    # using mean squared error as a loss metric\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.model(x)\n",
    "        return res\n",
    "\n",
    "    def train_epoch(self, x, y):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def train(self, train_data, epochs=500):\n",
    "        x, y = train_data\n",
    "        losses = []\n",
    "        for iter in range(epochs):\n",
    "            iteration_loss = self.train_epoch(x, y)\n",
    "            losses.append(iteration_loss)\n",
    "            if iter and iter % 5 == 0:\n",
    "                print(f\"iteration {iter}/{epochs}, loss = {iteration_loss}\")\n",
    "        return losses\n",
    "\n",
    "    def validation_loss(self, test_data):\n",
    "        x, y = test_data\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        return loss.item()\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c63b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['actions', 'infos', 'metadata', 'next_observations', 'observations', 'rewards', 'terminals', 'timeouts']>\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = h5py.File(Path(\"./halfcheetah_medium-v2.hdf5\"))\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8db56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape = (1000000, 6)\n",
      "s shape = (1000000, 17)\n",
      "s_new shape = (1000000, 17)\n",
      "r shape = (1000000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract relevant cols\n",
    "a = data[\"actions\"]\n",
    "s_new = data[\"next_observations\"]\n",
    "s = data[\"observations\"]\n",
    "r = data[\"rewards\"]\n",
    "\n",
    "# info\n",
    "print(\n",
    "    f\"a shape = {a.shape}\\n\" \\\n",
    "    f\"s shape = {s.shape}\\n\" \\\n",
    "    f\"s_new shape = {s_new.shape}\\n\" \\\n",
    "    f\"r shape = {r.shape}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21844542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape = torch.Size([800000, 23])\n",
      "x_test shape = torch.Size([200000, 23])\n",
      "y_train shape = torch.Size([800000, 18])\n",
      "y_test shape = torch.Size([200000, 18])\n"
     ]
    }
   ],
   "source": [
    "# divide data\n",
    "x = np.hstack([a, s])                                # -> (N, 23)\n",
    "y = np.hstack([s_new, np.array(r).reshape(-1, 1)])   # -> (N, 18)\n",
    "\n",
    "# converting to tensors\n",
    "x = torch.tensor(x, dtype=torch.float32)   \n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "# info\n",
    "print(\n",
    "    f\"x_train shape = {x_train.shape}\\n\" \\\n",
    "    f\"x_test shape = {x_test.shape}\\n\" \\\n",
    "    f\"y_train shape = {y_train.shape}\\n\" \\\n",
    "    f\"y_test shape = {y_test.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d7c8297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5/200, loss = 19.004230499267578\n",
      "iteration 10/200, loss = 16.140222549438477\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m model = Network()\n\u001b[32m      9\u001b[39m model = model.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mNetwork.train\u001b[39m\u001b[34m(self, train_data, epochs)\u001b[39m\n\u001b[32m     34\u001b[39m losses = []\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     iteration_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     losses.append(iteration_loss)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28miter\u001b[39m % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mNetwork.train_epoch\u001b[39m\u001b[34m(self, x, y)\u001b[39m\n\u001b[32m     25\u001b[39m y_hat = \u001b[38;5;28mself\u001b[39m.model(x)\n\u001b[32m     26\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.criterion(y_hat, y)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.step()\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = x_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test.to(device)\n",
    "train_data = (x_train, y_train)\n",
    "model = Network()\n",
    "model = model.to(device)\n",
    "model.train(train_data, epochs=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
