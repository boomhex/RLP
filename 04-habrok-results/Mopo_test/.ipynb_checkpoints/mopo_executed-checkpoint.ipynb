{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9087d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:17.421363Z",
     "iopub.status.busy": "2025-12-15T15:44:17.420580Z",
     "iopub.status.idle": "2025-12-15T15:44:22.301454Z",
     "shell.execute_reply": "2025-12-15T15:44:22.299512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /home4/s5231795/venvs/habrok/lib/python3.10/site-packages (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home4/s5231795/venvs/habrok/lib/python3.10/site-packages (from h5py) (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e81ec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:22.308377Z",
     "iopub.status.busy": "2025-12-15T15:44:22.307833Z",
     "iopub.status.idle": "2025-12-15T15:44:29.157207Z",
     "shell.execute_reply": "2025-12-15T15:44:29.155596Z"
    }
   },
   "outputs": [],
   "source": [
    "# import NN necessities:\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# import plotting utilities:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import data preprocessing utilities:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2718ddfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:29.163611Z",
     "iopub.status.busy": "2025-12-15T15:44:29.162974Z",
     "iopub.status.idle": "2025-12-15T15:44:29.178826Z",
     "shell.execute_reply": "2025-12-15T15:44:29.177702Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):   # class defining a basic nn\n",
    "\n",
    "    def __init__(self, h_size=200):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(23, h_size),      # in\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_size, h_size),    # hidden, 3 layers\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_size, h_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_size, h_size),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(h_size, 18)       # out\n",
    "        )\n",
    "        self.mean_head = nn.Linear(h_size, 18)\n",
    "        self.logvar_head = nn.Linear(h_size, 18)\n",
    "\n",
    "        # bind log-variance to avoid numerical instability\n",
    "        self.max_logvar = nn.Parameter(torch.ones(18) * 0.5)\n",
    "        self.min_logvar = nn.Parameter(torch.ones(18) * -10)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.criterion = nn.MSELoss()    # using mean squared error as a loss metric\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.model(x)\n",
    "        mean = self.mean_head(res)\n",
    "        logvar = self.logvar_head(res)\n",
    "\n",
    "        # clamp log-variance using soft constraints (see MBPO/PETS)\n",
    "        logvar = self.max_logvar - torch.nn.functional.softplus(self.max_logvar - logvar)\n",
    "        logvar = self.min_logvar + torch.nn.functional.softplus(logvar - self.min_logvar)\n",
    "        return mean, logvar\n",
    "\n",
    "    def nll_loss(self, x, y):\n",
    "        \"\"\"\n",
    "        Negative log-likelihood of Gaussian:\n",
    "            NLL = 0.5 * [ logσ² + (y - µ)² / σ² ]\n",
    "        \"\"\"\n",
    "        mean, logvar = self.forward(x)\n",
    "        var = torch.exp(logvar)\n",
    "\n",
    "        nll = 0.5 * ((y - mean)**2 / var + logvar)\n",
    "        return nll.mean()\n",
    "\n",
    "    def train_epoch(self, x, y):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        loss = self.nll_loss(x, y)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def train(self, train_data, epochs=500, cp=100):\n",
    "        x, y = train_data\n",
    "\n",
    "        # again split the data to optimize hyperparam on val set, not leak data.\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "    \n",
    "        test_losses = []\n",
    "        losses = []\n",
    "    \n",
    "        for iter in range(epochs):\n",
    "            # train\n",
    "            iteration_loss = self.train_epoch(x_train, y_train)\n",
    "            losses.append(iteration_loss)\n",
    "\n",
    "            # validate\n",
    "            val_loss = self.validation_loss((x_val, y_val))\n",
    "            test_losses.append(val_loss)\n",
    "    \n",
    "            # print\n",
    "            if iter and iter % cp == 0:    # update on iteration checkpoints\n",
    "                print(f\"iteration {iter}/{epochs}, loss = {iteration_loss}, {val_loss}\")\n",
    "        \n",
    "        return losses, test_losses\n",
    "\n",
    "\n",
    "    def validation_loss(self, test_data):\n",
    "        x, y = test_data\n",
    "        loss = self.nll_loss(x, y)\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c63b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:29.183062Z",
     "iopub.status.busy": "2025-12-15T15:44:29.182901Z",
     "iopub.status.idle": "2025-12-15T15:44:29.237745Z",
     "shell.execute_reply": "2025-12-15T15:44:29.235920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['actions', 'infos', 'metadata', 'next_observations', 'observations', 'rewards', 'terminals', 'timeouts']>\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = h5py.File(Path(\"./halfcheetah_medium-v2.hdf5\"))\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b8db56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:29.242936Z",
     "iopub.status.busy": "2025-12-15T15:44:29.242094Z",
     "iopub.status.idle": "2025-12-15T15:44:29.284004Z",
     "shell.execute_reply": "2025-12-15T15:44:29.282068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape = (1000000, 6)\n",
      "s shape = (1000000, 17)\n",
      "s_new shape = (1000000, 17)\n",
      "r shape = (1000000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract relevant cols\n",
    "a = data[\"actions\"]\n",
    "s_new = data[\"next_observations\"]\n",
    "s = data[\"observations\"]\n",
    "r = data[\"rewards\"]\n",
    "\n",
    "# info\n",
    "print(\n",
    "    f\"a shape = {a.shape}\\n\" \\\n",
    "    f\"s shape = {s.shape}\\n\" \\\n",
    "    f\"s_new shape = {s_new.shape}\\n\" \\\n",
    "    f\"r shape = {r.shape}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21844542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:29.288886Z",
     "iopub.status.busy": "2025-12-15T15:44:29.288044Z",
     "iopub.status.idle": "2025-12-15T15:44:30.617899Z",
     "shell.execute_reply": "2025-12-15T15:44:30.616643Z"
    }
   },
   "outputs": [],
   "source": [
    "# divide data\n",
    "x = np.hstack([a, s])                                # -> (N, 23)\n",
    "y = np.hstack([s_new, np.array(r).reshape(-1, 1)])   # -> (N, 18)\n",
    "\n",
    "# converting to tensors\n",
    "x = torch.tensor(x, dtype=torch.float32)   \n",
    "y = torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a6fe80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:30.619938Z",
     "iopub.status.busy": "2025-12-15T15:44:30.619704Z",
     "iopub.status.idle": "2025-12-15T15:44:30.623502Z",
     "shell.execute_reply": "2025-12-15T15:44:30.623031Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# your Network class exactly as you gave it above ...\n",
    "# (no need to change it)\n",
    "\n",
    "def validation_mse(model: Network, x_val: torch.Tensor, y_val: torch.Tensor, device) -> float:\n",
    "    \"\"\"Compute MSE on validation set using the mean head of the model.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        mean, _ = model.forward(x_val.to(device))\n",
    "        mse = nn.MSELoss()(mean.to(device), y_val.to(device))\n",
    "    return mse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04f3661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:30.625301Z",
     "iopub.status.busy": "2025-12-15T15:44:30.625141Z",
     "iopub.status.idle": "2025-12-15T15:44:30.630455Z",
     "shell.execute_reply": "2025-12-15T15:44:30.629619Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_size_sweep(x: torch.Tensor, y: torch.Tensor,\n",
    "                   max_epochs: int = 100,\n",
    "                   n_sizes: int = 20):\n",
    "    \"\"\"\n",
    "    Train networks with different hidden sizes and record validation MSE curves.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hidden_sizes : list[int]\n",
    "    val_mse_curves : np.ndarray of shape (n_sizes, max_epochs)\n",
    "    \"\"\"\n",
    "    # split once so all models see the same train/val split\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x, y, test_size=0.2, shuffle=True\n",
    "    )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"using device: {device}\")\n",
    "    \n",
    "    x_train = x_train.to(device)\n",
    "    x_test = x_val.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    y_test = y_val.to(device)\n",
    "\n",
    "    # choose 20 hidden sizes, e.g. from 20 to 400\n",
    "    hidden_sizes = np.linspace(20, 150, n_sizes, dtype=int)\n",
    "\n",
    "    val_mse_curves = np.zeros((n_sizes, max_epochs))\n",
    "    \n",
    "\n",
    "    for i, h_size in enumerate(hidden_sizes):\n",
    "        print(f\"\\n=== Training model with h_size = {h_size} ===\")\n",
    "        arr = [-1,-1,-1]\n",
    "        for j in range(3):\n",
    "            net = Network(h_size=h_size)\n",
    "            net = net.to(device)\n",
    "\n",
    "            net.train((x_train,y_train), epochs=max_epochs, cp=20)\n",
    "\n",
    "                # compute validation MSE\n",
    "            mse_val = validation_mse(net, x_val, y_val, device)\n",
    "            arr[j] = mse_val\n",
    "            \n",
    "        val_mse_curves[i, max_epochs-1] = sum(arr)/3\n",
    "\n",
    "    return hidden_sizes, val_mse_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ed59497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T15:44:30.632474Z",
     "iopub.status.busy": "2025-12-15T15:44:30.632318Z",
     "iopub.status.idle": "2025-12-15T15:44:51.058065Z",
     "shell.execute_reply": "2025-12-15T15:44:51.056571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "\n",
      "=== Training model with h_size = 20 ===\n",
      "iteration 20/1000, loss = 16.858192443847656, 16.77446746826172\n",
      "iteration 40/1000, loss = 15.313017845153809, 15.173742294311523\n",
      "iteration 60/1000, loss = 12.105244636535645, 11.89573860168457\n",
      "iteration 80/1000, loss = 10.026976585388184, 9.982769966125488\n",
      "iteration 100/1000, loss = 9.196648597717285, 9.154703140258789\n",
      "iteration 120/1000, loss = 8.791984558105469, 8.770336151123047\n",
      "iteration 140/1000, loss = 8.592769622802734, 8.575713157653809\n",
      "iteration 160/1000, loss = 8.433412551879883, 8.416902542114258\n",
      "iteration 180/1000, loss = 8.280312538146973, 8.26339054107666\n",
      "iteration 200/1000, loss = 8.134687423706055, 8.118396759033203\n",
      "iteration 220/1000, loss = 8.007392883300781, 7.992436408996582\n",
      "iteration 240/1000, loss = 7.909576416015625, 7.896133899688721\n",
      "iteration 260/1000, loss = 7.837104320526123, 7.824638843536377\n",
      "iteration 280/1000, loss = 7.780427932739258, 7.7683424949646\n",
      "iteration 300/1000, loss = 7.731713771820068, 7.719778060913086\n",
      "iteration 320/1000, loss = 7.6897430419921875, 7.677856922149658\n",
      "iteration 340/1000, loss = 7.653384685516357, 7.641543865203857\n",
      "iteration 360/1000, loss = 7.619629383087158, 7.607844352722168\n",
      "iteration 380/1000, loss = 7.587958335876465, 7.57639741897583\n",
      "iteration 400/1000, loss = 7.558811187744141, 7.5472846031188965\n",
      "iteration 420/1000, loss = 7.530513763427734, 7.51898193359375\n",
      "iteration 440/1000, loss = 7.502068042755127, 7.490480422973633\n",
      "iteration 460/1000, loss = 7.472737789154053, 7.46111536026001\n",
      "iteration 480/1000, loss = 7.442690372467041, 7.4310832023620605\n",
      "iteration 500/1000, loss = 7.4117512702941895, 7.4001264572143555\n",
      "iteration 520/1000, loss = 7.379479885101318, 7.367858409881592\n",
      "iteration 540/1000, loss = 7.345656871795654, 7.334179401397705\n",
      "iteration 560/1000, loss = 7.308013916015625, 7.2937822341918945\n",
      "iteration 580/1000, loss = 7.182490825653076, 7.17191743850708\n",
      "iteration 600/1000, loss = 7.135075569152832, 7.124391078948975\n",
      "iteration 620/1000, loss = 7.102831840515137, 7.091662406921387\n",
      "iteration 640/1000, loss = 7.076323509216309, 7.065750598907471\n",
      "iteration 660/1000, loss = 7.050529479980469, 7.040037631988525\n",
      "iteration 680/1000, loss = 7.027495861053467, 7.017091751098633\n",
      "iteration 700/1000, loss = 7.0068159103393555, 6.996624946594238\n",
      "iteration 720/1000, loss = 6.98793888092041, 6.977968215942383\n",
      "iteration 740/1000, loss = 6.9700846672058105, 6.959423065185547\n",
      "iteration 760/1000, loss = 6.954841613769531, 6.944431304931641\n",
      "iteration 780/1000, loss = 6.938083648681641, 6.928071022033691\n",
      "iteration 800/1000, loss = 6.9251933097839355, 6.914829254150391\n",
      "iteration 820/1000, loss = 6.91040563583374, 6.900835990905762\n",
      "iteration 840/1000, loss = 6.898080825805664, 6.887477397918701\n",
      "iteration 860/1000, loss = 6.88503885269165, 6.875307559967041\n",
      "iteration 880/1000, loss = 6.874191761016846, 6.8640217781066895\n",
      "iteration 900/1000, loss = 6.861914157867432, 6.852554798126221\n",
      "iteration 920/1000, loss = 6.853176593780518, 6.843087673187256\n",
      "iteration 940/1000, loss = 6.842073917388916, 6.832651615142822\n",
      "iteration 960/1000, loss = 6.835153579711914, 6.82572078704834\n",
      "iteration 980/1000, loss = 6.825078010559082, 6.816109657287598\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hidden_sizes, val_mse_curves \u001b[38;5;241m=\u001b[39m \u001b[43mrun_size_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m final_mse \u001b[38;5;241m=\u001b[39m val_mse_curves[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# MSE after last epoch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m, in \u001b[0;36mrun_size_sweep\u001b[0;34m(x, y, max_epochs, n_sizes)\u001b[0m\n\u001b[1;32m     37\u001b[0m     net\u001b[38;5;241m.\u001b[39mtrain((x_train,y_train), epochs\u001b[38;5;241m=\u001b[39mmax_epochs, cp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# compute validation MSE\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     mse_val \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_mse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     arr[j] \u001b[38;5;241m=\u001b[39m mse_val\n\u001b[1;32m     43\u001b[0m val_mse_curves[i, max_epochs\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(arr)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mvalidation_mse\u001b[0;34m(model, x_val, y_val)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute MSE on validation set using the mean head of the model.\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 14\u001b[0m     mean, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x_val\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m))\n\u001b[1;32m     15\u001b[0m     mse \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(mean\u001b[38;5;241m.\u001b[39mto(device), y_val\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mse\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "hidden_sizes, val_mse_curves = run_size_sweep(x, y, max_epochs=1000, n_sizes=50)\n",
    "\n",
    "final_mse = val_mse_curves[:, -1]  # MSE after last epoch\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hidden_sizes, final_mse, marker=\"o\")\n",
    "plt.xlabel(\"Hidden layer size (h_size)\")\n",
    "plt.ylabel(\"Validation MSE (final epoch)\")\n",
    "plt.title(\"Final validation MSE vs. model size\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c513bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35c96c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
